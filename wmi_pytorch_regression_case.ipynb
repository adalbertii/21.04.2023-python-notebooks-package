{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAI/fEQA9+iZ7In2gnXcA2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalbertii/phyton-binder/blob/main/wmi_pytorch_regression_case.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Educational Friday: 21.04.2023**\n",
        "\n",
        "\n",
        "---\n",
        "Developed by Wojciech Michalski\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Building neural network  - regresion model case\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "With use: PyTorch library\n",
        "\n"
      ],
      "metadata": {
        "id": "YE6Cea00wZu4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pobranie danych uczących i danych walidujących"
      ],
      "metadata": {
        "id": "UWgToMwpzUON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "data = fetch_california_housing()\n",
        "print(data.feature_names)\n",
        "X, y = data.data, data.target"
      ],
      "metadata": {
        "id": "0rExWGYvzgGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bodowa modelu sieci neuronowej"
      ],
      "metadata": {
        "id": "YtCZuykMzwBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "# Define the model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(8, 24),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(24, 12),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(12, 6),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(6, 1)\n",
        ")"
      ],
      "metadata": {
        "id": "ogDKy9Pzz5Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definicja funkcji błędu uczenia oraz algorytmu optymalizacji sieci"
      ],
      "metadata": {
        "id": "rM-67Vd40-4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim \n",
        "# loss function and optimizer\n",
        "loss_fn = nn.MSELoss()  # mean square error\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "xv3jings1Jv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proces uczenia sieci"
      ],
      "metadata": {
        "id": "yhNlKDsl1cNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "# train-test split of the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
        " \n",
        "# training parameters\n",
        "n_epochs = 20   # number of epochs to run\n",
        "batch_size = 10  # size of each batch\n",
        "batch_start = torch.arange(0, len(X_train), batch_size)\n",
        " \n",
        "# Hold the best model\n",
        "best_mse = np.inf   # init to infinity\n",
        "best_weights = None\n",
        "history = []\n",
        " \n",
        "# training loop\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
        "        bar.set_description(f\"Epoch {epoch}\")\n",
        "        for start in bar:\n",
        "            # take a batch\n",
        "            X_batch = X_train[start:start+batch_size]\n",
        "            y_batch = y_train[start:start+batch_size]\n",
        "            # forward pass\n",
        "            y_pred = model(X_batch)\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "            # backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            # update weights\n",
        "            optimizer.step()\n",
        "            # print progress\n",
        "            bar.set_postfix(mse=float(loss))\n",
        "    # evaluate accuracy at end of each epoch\n",
        "    model.eval()\n",
        "    y_pred = model(X_test)\n",
        "    mse = loss_fn(y_pred, y_test)\n",
        "    mse = float(mse)\n",
        "    history.append(mse)\n",
        "    if mse < best_mse:\n",
        "        best_mse = mse\n",
        "        best_weights = copy.deepcopy(model.state_dict())\n",
        " \n",
        "# restore model and return best accuracy\n",
        "model.load_state_dict(best_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32J2WKh31huv",
        "outputId": "00d09a50-a233-4391-9c85-9a0a899e9614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Charakterystyka wytrenowanego modelu sieci"
      ],
      "metadata": {
        "id": "wT5Pa6hk1_A5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(\"MSE: %.2f\" % best_mse)\n",
        "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
        "plt.plot(history)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vtTFxQYJ2Io6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model sieci neuronowej z ustandaryzowanymi danymi wejściowymi \n",
        "Kompletny kod programu"
      ],
      "metadata": {
        "id": "otsdPPtS2x1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        " \n",
        "# Read data\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        " \n",
        "# train-test split for model evaluation\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
        " \n",
        "# Standardizing data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train_raw)\n",
        "X_train = scaler.transform(X_train_raw)\n",
        "X_test = scaler.transform(X_test_raw)\n",
        " \n",
        "# Convert to 2D PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
        " \n",
        "# Define the model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(8, 24),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(24, 12),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(12, 6),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(6, 1)\n",
        ")\n",
        " \n",
        "# loss function and optimizer\n",
        "loss_fn = nn.MSELoss()  # mean square error\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        " \n",
        "n_epochs = 30   # number of epochs to run\n",
        "batch_size = 10  # size of each batch\n",
        "batch_start = torch.arange(0, len(X_train), batch_size)\n",
        " \n",
        "# Hold the best model\n",
        "best_mse = np.inf   # init to infinity\n",
        "best_weights = None\n",
        "history = []\n",
        " \n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
        "        bar.set_description(f\"Epoch {epoch}\")\n",
        "        for start in bar:\n",
        "            # take a batch\n",
        "            X_batch = X_train[start:start+batch_size]\n",
        "            y_batch = y_train[start:start+batch_size]\n",
        "            # forward pass\n",
        "            y_pred = model(X_batch)\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "            # backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            # update weights\n",
        "            optimizer.step()\n",
        "            # print progress\n",
        "            bar.set_postfix(mse=float(loss))\n",
        "    # evaluate accuracy at end of each epoch\n",
        "    model.eval()\n",
        "    y_pred = model(X_test)\n",
        "    mse = loss_fn(y_pred, y_test)\n",
        "    mse = float(mse)\n",
        "    history.append(mse)\n",
        "    if mse < best_mse:\n",
        "        best_mse = mse\n",
        "        best_weights = copy.deepcopy(model.state_dict())\n",
        " \n",
        "# restore model and return best accuracy\n",
        "model.load_state_dict(best_weights)\n",
        "print(\"MSE: %.2f\" % best_mse)\n",
        "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
        "plt.plot(history)\n",
        "plt.show()\n",
        " \n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Test out inference with 5 samples\n",
        "    for i in range(5):\n",
        "        X_sample = X_test_raw[i: i+1]\n",
        "        X_sample = scaler.transform(X_sample)\n",
        "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
        "        y_pred = model(X_sample)\n",
        "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "RTQbESbU28Q3",
        "outputId": "5cd91ccf-0219-48bf-e921-4b528f6a0a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.34\n",
            "RMSE: 0.58\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 4.23910000e+00  5.00000000e+00  5.12380952e+00  9.33333333e-01\n",
            "  8.73300000e+03  8.31714286e+01  3.44700000e+01 -1.18590000e+02] -> [2.880638] (expected [1.546])\n",
            "[ 6.43190000e+00  3.40000000e+01  6.51404494e+00  9.38202247e-01\n",
            "  9.41000000e+02  2.64325843e+00  3.39500000e+01 -1.18110000e+02] -> [3.4352903] (expected [4.523])\n",
            "[   3.0694       44.            5.38585209    1.0192926   806.\n",
            "    2.59163987   37.95       -122.34      ] -> [1.7593583] (expected [1.353])\n",
            "[ 2.16410000e+00  3.10000000e+01  3.80904523e+00  1.00502513e+00\n",
            "  1.82000000e+03  4.57286432e+00  3.39300000e+01 -1.18180000e+02] -> [1.326714] (expected [1.229])\n",
            "[ 2.54300000e+00  1.50000000e+01  4.87709497e+00  1.11545624e+00\n",
            "  1.51300000e+03  2.81750466e+00  3.28100000e+01 -1.16950000e+02] -> [1.4771143] (expected [1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Test out inference with 5 samples\n",
        "    for i in range(50):\n",
        "        X_sample = X_test_raw[i: i+1]\n",
        "        X_sample = scaler.transform(X_sample)\n",
        "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
        "        y_pred = model(X_sample)\n",
        "        print(f\"{y_pred[0].numpy()} (expected {y_test[i].numpy()})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5EE_fNP7isN",
        "outputId": "364bae74-b20c-4bb9-a7fe-18c6ad583a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.880638] (expected [1.546])\n",
            "[3.4352903] (expected [4.523])\n",
            "[1.7593583] (expected [1.353])\n",
            "[1.326714] (expected [1.229])\n",
            "[1.4771143] (expected [1.])\n",
            "[1.9272652] (expected [0.283])\n",
            "[3.3198137] (expected [3.714])\n",
            "[3.2100155] (expected [2.469])\n",
            "[1.3627675] (expected [1.648])\n",
            "[1.2806917] (expected [1.431])\n",
            "[3.3593497] (expected [3.375])\n",
            "[1.4109303] (expected [0.875])\n",
            "[1.3414384] (expected [0.983])\n",
            "[3.2121227] (expected [3.447])\n",
            "[0.5160064] (expected [0.858])\n",
            "[1.0021582] (expected [0.771])\n",
            "[2.2006648] (expected [2.006])\n",
            "[2.0573711] (expected [2.374])\n",
            "[2.1425865] (expected [1.367])\n",
            "[2.4825768] (expected [2.337])\n",
            "[2.770143] (expected [2.05])\n",
            "[2.179395] (expected [2.578])\n",
            "[1.0771416] (expected [0.845])\n",
            "[4.8801436] (expected [5.00001])\n",
            "[1.2840844] (expected [0.886])\n",
            "[1.6709043] (expected [2.375])\n",
            "[2.1480105] (expected [2.07])\n",
            "[0.54968244] (expected [0.592])\n",
            "[2.7021666] (expected [4.309])\n",
            "[2.0235705] (expected [1.991])\n",
            "[0.8266989] (expected [0.475])\n",
            "[0.7597371] (expected [0.455])\n",
            "[1.7532083] (expected [1.606])\n",
            "[1.3412119] (expected [0.905])\n",
            "[5.074858] (expected [5.00001])\n",
            "[1.6682686] (expected [2.174])\n",
            "[2.116971] (expected [2.75])\n",
            "[2.5508676] (expected [4.333])\n",
            "[3.2764912] (expected [2.56])\n",
            "[1.479387] (expected [1.712])\n",
            "[0.7074565] (expected [0.715])\n",
            "[1.8128674] (expected [1.17])\n",
            "[1.3340629] (expected [1.505])\n",
            "[2.9664938] (expected [3.054])\n",
            "[2.418698] (expected [2.402])\n",
            "[1.3915555] (expected [1.526])\n",
            "[0.5745392] (expected [0.806])\n",
            "[1.7252532] (expected [1.855])\n",
            "[1.2279369] (expected [0.45])\n",
            "[2.80416] (expected [2.616])\n"
          ]
        }
      ]
    }
  ]
}